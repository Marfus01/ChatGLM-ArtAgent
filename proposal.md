# 美学知识增强的图像生成AI Proposal

## 背景&思路

### 1. 精确性

当前，对于 Text2Image 的精准性的优化思路主要有三：
* 一是在数据侧做增强，比如对数据集做精选、对出现数据分布不平均的地方做优化；
* 二是引入 Human Feedback 机制以或者通过美学数据集来进行评分；
* 三是如 ControlNet 一类的工作，在 LDM 的 Conditioning 做优化

我们之前在交流会上讨论过，有没有可能将一些艺术知识直接提供给AI？ 
为了实现这种效果，有两种方式可以尝试：
* 其一，为每一个艺术概念训练一个 Lora，将知识加入 LDM 中；
* 其二，让大语言模型作为辅助，利用大语言模型中已有的知识，或者通过微调增加的知识，来指导 Text2Image 过程。

其中，前者的工作量比较大，需要经过 搜集图片->数据标注->数据增强->Lora训练，而且在使用上并不灵便。

后者需要较强的专家背景，而这恰好是我们团队的优势所在。

### 2. 启发性

此外，Text2Image 的精准性，并不是其唯一的优化方向。

目前，对于 Text2Image 的使用场景分类可以分为四类：
* 美术背景使用者
  * 艺术家、美术学院学生，纯艺术方向
  * 设计师，如，室内设计师，海报制作者等
* 非美术背景使用者
  * 具体应用场景，如，淘宝店模特等
  * 玩家，兴趣/表达/libido驱动

对于包括设计师在内的存在具体应用场景的使用者而言，精确性确实是 Text2Image 最需要追求的，然而，对于艺术家、玩家等群体，更多的启发性，甚至是随机性，也是具有魅力的。

目前也有一些工作通过通配符来提供这些随机性：
* https://github.com/AUTOMATIC1111/stable-diffusion-webui-wildcards.git

然而这种工作是相对机械的，而事实上，最直接的提供随机性和启发性的便是语言讨论。

因为，我们选择尝试将 LLM 引入我们的链路。

### 3. 易用性

目前的 AUTOMATIC1111 WebUI 的界面非常复杂，可以调整的选项非常多，这是其集成了众多插件的体现，然而也成为其难以被普及的门槛。而仅仅是在 Prompt 的填写上，也存在一些“定式”，这些定式强烈地影响着画风，但却需要用户手工填写。

有一些工作尝试对 UI 进行简化：
* 固定一些 Prompt 和 其他参数 作为缺省选择，当用户只填写了一些关键名词时，基于规则地，为用户补充一些提高画面质量的固定搭配。
* 基于语言模型地，为用户自动补充、丰富 Prompt。

而在这样的过程中，画面的风格会受到较大的限制，而且用户也很难精准地描述自己所想要的图景。

### 总结

综上，精确性、易用性、启发性形成了图像生成AI应用的不可能三角，我们选择将一个略懂艺术的 LLM 作为 Interface 以平衡这三种因素。